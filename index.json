[{"authors":null,"categories":null,"content":"Seb Silas is a PhD Researcher at Hanover Music Lab, supervised by Reinhard Kopiez and Daniel Müllensiefen. He researches computational approaches to musical learning and memory, with a particular emphasis on learning melodies and playing by ear. He is an active music teacher and saxophonist, improviser and composer, most notably with the band Don’t Problem (see music website here). He draws upon his experience in these fields in his academic research.\nHe maintains the musicassessr and itembankr R packages and musical ability tests:\n Playing By Ear Test (PBET) Singing Ability Assessment (SAA) Sight Reading Test (SRT) Sight-Singing Test (SST) Pitch Discrimination Test (PDT)   Download my resumé. -- ","date":1649462400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1649462400,"objectID":"e6b32d5594ea8d187f3da043bcb5f094","permalink":"https://sebsilas.github.io/author/seb-silas/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/seb-silas/","section":"authors","summary":"Seb Silas is a PhD Researcher at Hanover Music Lab, supervised by Reinhard Kopiez and Daniel Müllensiefen. He researches computational approaches to musical learning and memory, with a particular emphasis on learning melodies and playing by ear.","tags":null,"title":"Seb Silas","type":"authors"},{"authors":["Seb Silas"],"categories":null,"content":"","date":1649462400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649462400,"objectID":"29a64b70a5b598a8052dba392157dfcb","permalink":"https://sebsilas.github.io/publication/working-memory-causality/","publishdate":"2022-04-09T00:00:00Z","relpermalink":"/publication/working-memory-causality/","section":"publication","summary":"Prior research studying the relationship between music training (MT) and more general cognitive faculties, such as visuospatial working memory (VSWM), often fails to include tests of musical memory...","tags":["working memory, music training, visuospatial working memory, causality"],"title":"The associations between music training, musical working memory and visuospatial working memory: an opportunity for causal modeling.","type":"publication"},{"authors":["Seb Silas"],"categories":null,"content":"","date":1643241600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643241600,"objectID":"524324bc1f993d18f12c90299c6c842d","permalink":"https://sebsilas.github.io/publication/jack-and-jill/","publishdate":"2022-01-27T00:00:00Z","relpermalink":"/publication/jack-and-jill/","section":"publication","summary":"The development of a new visuospatial working memory test.","tags":null,"title":"The Jack and Jill Adaptive Working Memory Task: Construction, Calibration and Validation.","type":"publication"},{"authors":["Seb Silas"],"categories":null,"content":"","date":1588204800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588204800,"objectID":"e1a78df64a3d3d1c969fc2f781f95cfe","permalink":"https://sebsilas.github.io/publication/piat/","publishdate":"2020-04-30T00:00:00Z","relpermalink":"/publication/piat/","section":"publication","summary":"The ability to silently hear music in the mind has been argued to be fundamental to musicality. Objective measurements of this subjective imagery experience are needed if this link between imagery ability and musicality is to be investigated. However, previous tests of musical imagery either rely on self-report, rely on melodic memory, or do not cater in range of abilities. The Pitch Imagery Arrow Task (PIAT) was designed to address these shortcomings; however, it is impractically long. In this paper, we shorten the PIAT using adaptive testing and automatic item generation. We interrogate the cognitive processes underlying the PIAT through item response modelling. The result is an efficient online test of auditory mental imagery ability (adaptive Pitch Imagery Arrow Task: aPIAT) that takes 8 min to complete, is adaptive to participant’s individual ability, and so can be used to test participants with a range of musical backgrounds. Performance on the aPIAT showed positive moderate-to-strong correlations with measures of non-musical and musical working memory, self-reported musical training, and general musical sophistication. Ability on the task was best predicted by the ability to maintain and manipulate tones in mental imagery, as well as to resist perceptual biases that can lead to incorrect responses. As such, the aPIAT is the ideal tool in which to investigate the relationship between pitch imagery ability and musicality.","tags":["musical imagery"],"title":"An efficient and adaptive test of auditory mental imagery","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"551c87797a2c92652a9f65ff2f30e084","permalink":"https://sebsilas.github.io/project/pbet/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/pbet/","section":"project","summary":"My PhD project is  about computational approaches to helping people memorise melodies, particularly in the context of `playing by ear`.","tags":["playing by ear","melodic memory","music learning"],"title":"Playing By Ear","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"c31961e9019aade8959c33489fee3d68","permalink":"https://sebsilas.github.io/project/sonic-branding/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/sonic-branding/","section":"project","summary":"A new project to create an ‘`emotional DNA map`’ that can predict the subconscious impact music used in marketing has on consumers.","tags":["sonic branding","audio branding","emotional DNA"],"title":"Sonic branding","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"ff53caf55e992c1e956721d926986d69","permalink":"https://sebsilas.github.io/project/wagner30/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/wagner30/","section":"project","summary":"Immersive sound environments and their potential for creating musical experience and cultural participation.","tags":["immersive audio","3d sound"],"title":"Wagner 3.0","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://sebsilas.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":["Sebastian Silas","Daniel Müllensiefen","David Baker"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c8bbed92ae057c35f9c1a4b5ebaf71c7","permalink":"https://sebsilas.github.io/talk/changing-the-emotional-semantic-perception-of-visual-scenes-with-music-a-large-scale-investigation-into-the-effects-of-audio-branding./","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talk/changing-the-emotional-semantic-perception-of-visual-scenes-with-music-a-large-scale-investigation-into-the-effects-of-audio-branding./","section":"event","summary":"Advertisements frequently pair music with visual imagery to convey information about brand value or identity (Allan, 2008). Whilst such pairings have been investigated in film music research (Cohen, 2014), they have received less attention in advertising research. Dual-process models of decision-making, which posit both implicit and explicit channels for processing incoming cognitive information, are important to consider. Hence, we aimed to build a new quantitative testing procedure to determine the effects of music on the evaluation of short visual stimuli and investigated: a) to what degree music is able to alter the semantic content of visual scenes and b) the magnitude of differences between explicit and implicit semantic ratings of visual-music pairings. Across three experiments (N = 2,642, N = 1,554, N = 251), participants rated the semantic content of short videos paired with audio stimuli taken from two corpora of professionally produced audio assets (1. Brand anthems, ~30s; 2. Audio logos, ~5s). Results indicate that, overall, visual information dominates audio information in the interpretation of visual scenes. However, using variance component analysis and generalization theory (Brennan, 2001), we demonstrate how, through item selection, subsets of videos can be used to form a test with high internal generalizability (equivalent alpha reliability = .95) and sensitivity (i.e. audio explaining between 20.49% and 36.68% of variance in ratings of 14 emotional-semantic attributes). The ratings of audio branding assets from our new implicit test correlate substantially with traditional explicit ratings of the same audio assets, but correlations vary considerably by attribute (r = .16 - .74). We discuss a) our robust modeling of the influence of music on visual scenes based on substantial empirical evidence, b) our novel approach for testing the emotional-semantic content of music in audio branding contexts using an implicit assessment procedure and c) the differences between implicit  and explicit assessments of music.","tags":["music and advertising"],"title":"Changing the emotional-semantic perception of visual scenes with music: A large-scale investigation into the effects of audio branding.","type":"event"}]